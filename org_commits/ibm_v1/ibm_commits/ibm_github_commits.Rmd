---
title: "ibm_github_commits.Rmd"
author: "Augustina Ragwitz"
date: "January 30, 2018"
output: html_document
params:
  gh_id: !r Sys.getenv("API_KEY_GITHUB_ID")
  gh_secret: !r Sys.getenv("API_KEY_GITHUB_SECRET")
---

```{r includes}
library(dplyr)
library(ggplot2)
library(gh)
library(httr)
library(jsonlite)
library(readr)
library(stringr)
library(tidyr)
```


Use the Github search API to pull commits for different time periods. See [https://developer.github.com/v3/search/#search-commits]

```{r github_search_commits}

query_params <- list(
  client_id=params$gh_id, 
  client_secret=params$gh_secret, 
  per_page=100)

get_gh_commits <- function (url, query) {
  req <- GET(url, query=query, accept("application/vnd.github.cloak-preview"))
  print(paste(req$url))
  json <- content(req, as = "text")
  commits <- fromJSON(json, flatten=TRUE)
  return(commits)
}
```

```{r search_gh_commits}
commits_search_url <- "https://api.github.com/search/commits"
commits_search_query <- "q=ibm.com+author-date:>2018-01-01"
url <- paste(commits_search_url, commits_search_query, sep="?")

commits_p1 <- get_gh_commits(url, append(query_params, c(page=1)))
total_pages <- ceiling(commits_p1$total_count[[1]]/100)

commits <- as.data.frame(commits_p1)
for (n in 2:total_pages) {
  print(paste("Getting commits for page:", n))
  search_result <- get_gh_commits(url, append(query_params, c(page=n)))
  commits <- bind_rows(commits, as.data.frame(search_result))
  saveRDS(commits, paste0("downloads/ibm_commits/_ibm_commits_", n, ".rds"))
}

saveRDS(commits, "data/ibm_commits.rds")
```


